classifier,oversampling,undersampling,classification_report,f_score_news,f_score_opinion,f_score_fake
randomforest,False,False,"              precision    recall  f1-score   support

        news       0.63      0.48      0.54        84
     opinion       0.76      0.94      0.84       229
   fake_news       0.57      0.17      0.26        47

    accuracy                           0.73       360
   macro avg       0.66      0.53      0.55       360
weighted avg       0.71      0.73      0.70       360
",0.5442176870748299,0.83984375,0.2622950819672131
randomforest,False,False,"              precision    recall  f1-score   support

        news       0.59      0.52      0.55        65
     opinion       0.82      0.96      0.88       253
   fake_news       0.60      0.07      0.13        42

    accuracy                           0.78       360
   macro avg       0.67      0.52      0.52       360
weighted avg       0.75      0.78      0.74       360
",0.5528455284552846,0.8836363636363638,0.1276595744680851
randomforest,False,False,"              precision    recall  f1-score   support

        news       0.60      0.48      0.53        81
     opinion       0.74      0.92      0.82       232
   fake_news       0.57      0.09      0.15        47

    accuracy                           0.71       360
   macro avg       0.64      0.49      0.50       360
weighted avg       0.69      0.71      0.67       360
",0.5342465753424657,0.8192307692307692,0.1481481481481481
randomforest,False,False,"              precision    recall  f1-score   support

        news       0.53      0.42      0.47        73
     opinion       0.77      0.93      0.84       240
   fake_news       0.83      0.21      0.34        47

    accuracy                           0.73       360
   macro avg       0.71      0.52      0.55       360
weighted avg       0.73      0.73      0.70       360
",0.4696969696969696,0.8393194706994329,0.3389830508474576
randomforest,False,False,"              precision    recall  f1-score   support

        news       0.53      0.45      0.49        64
     opinion       0.79      0.93      0.85       248
   fake_news       0.91      0.21      0.34        48

    accuracy                           0.75       360
   macro avg       0.74      0.53      0.56       360
weighted avg       0.76      0.75      0.72       360
",0.4873949579831932,0.8523985239852397,0.3389830508474576
randomforest,False,False,"              precision    recall  f1-score   support

        news       0.50      0.34      0.40        68
     opinion       0.77      0.93      0.84       244
   fake_news       0.71      0.25      0.37        48

    accuracy                           0.73       360
   macro avg       0.66      0.51      0.54       360
weighted avg       0.71      0.73      0.70       360
",0.4035087719298246,0.8428835489833642,0.3692307692307692
randomforest,False,False,"              precision    recall  f1-score   support

        news       0.62      0.43      0.51        67
     opinion       0.79      0.95      0.86       250
   fake_news       0.90      0.21      0.34        43

    accuracy                           0.77       360
   macro avg       0.77      0.53      0.57       360
weighted avg       0.77      0.77      0.73       360
",0.5087719298245613,0.860759493670886,0.339622641509434
randomforest,False,False,"              precision    recall  f1-score   support

        news       0.56      0.44      0.49        75
     opinion       0.74      0.93      0.82       227
   fake_news       0.79      0.19      0.31        58

    accuracy                           0.71       360
   macro avg       0.69      0.52      0.54       360
weighted avg       0.71      0.71      0.67       360
",0.4925373134328358,0.8249027237354085,0.3055555555555555
randomforest,False,False,"              precision    recall  f1-score   support

        news       0.58      0.47      0.52        72
     opinion       0.74      0.94      0.83       236
   fake_news       0.50      0.04      0.07        52

    accuracy                           0.71       360
   macro avg       0.61      0.48      0.47       360
weighted avg       0.68      0.71      0.66       360
",0.5190839694656489,0.8292682926829268,0.0714285714285714
randomforest,False,False,"              precision    recall  f1-score   support

        news       0.48      0.45      0.46        65
     opinion       0.76      0.92      0.83       240
   fake_news       0.83      0.18      0.30        55

    accuracy                           0.72       360
   macro avg       0.69      0.51      0.53       360
weighted avg       0.72      0.72      0.68       360
",0.464,0.8333333333333334,0.2985074626865672
randomforest,False,True,"              precision    recall  f1-score   support

        news       0.37      0.82      0.51        84
     opinion       0.87      0.57      0.69       229
   fake_news       0.38      0.19      0.25        47

    accuracy                           0.58       360
   macro avg       0.54      0.53      0.48       360
weighted avg       0.69      0.58      0.59       360
",0.5111111111111112,0.6860158311345647,0.2535211267605634
randomforest,False,True,"              precision    recall  f1-score   support

        news       0.34      0.89      0.50        65
     opinion       0.95      0.62      0.75       253
   fake_news       0.28      0.17      0.21        42

    accuracy                           0.62       360
   macro avg       0.52      0.56      0.48       360
weighted avg       0.76      0.62      0.64       360
",0.4957264957264957,0.7494033412887828,0.208955223880597
randomforest,False,True,"              precision    recall  f1-score   support

        news       0.39      0.84      0.53        81
     opinion       0.90      0.62      0.74       232
   fake_news       0.48      0.23      0.31        47

    accuracy                           0.62       360
   macro avg       0.59      0.57      0.53       360
weighted avg       0.73      0.62      0.64       360
",0.5291828793774318,0.737913486005089,0.3142857142857143
randomforest,False,True,"              precision    recall  f1-score   support

        news       0.35      0.92      0.50        73
     opinion       0.91      0.52      0.66       240
   fake_news       0.38      0.23      0.29        47

    accuracy                           0.56       360
   macro avg       0.54      0.56      0.48       360
weighted avg       0.72      0.56      0.58       360
",0.50187265917603,0.6578249336870027,0.2894736842105263
randomforest,False,True,"              precision    recall  f1-score   support

        news       0.32      0.84      0.46        64
     opinion       0.89      0.62      0.73       248
   fake_news       0.65      0.23      0.34        48

    accuracy                           0.61       360
   macro avg       0.62      0.56      0.51       360
weighted avg       0.75      0.61      0.63       360
",0.463519313304721,0.7298578199052134,0.3384615384615385
randomforest,False,True,"              precision    recall  f1-score   support

        news       0.33      0.87      0.48        68
     opinion       0.88      0.57      0.69       244
   fake_news       0.52      0.27      0.36        48

    accuracy                           0.59       360
   macro avg       0.58      0.57      0.51       360
weighted avg       0.73      0.59      0.61       360
",0.4816326530612244,0.6915422885572139,0.3561643835616438
randomforest,False,True,"              precision    recall  f1-score   support

        news       0.33      0.81      0.47        67
     opinion       0.87      0.61      0.72       250
   fake_news       0.50      0.23      0.32        43

    accuracy                           0.60       360
   macro avg       0.57      0.55      0.50       360
weighted avg       0.73      0.60      0.62       360
",0.4655172413793103,0.7200000000000001,0.3174603174603174
randomforest,False,True,"              precision    recall  f1-score   support

        news       0.33      0.75      0.46        75
     opinion       0.84      0.63      0.72       227
   fake_news       0.55      0.19      0.28        58

    accuracy                           0.58       360
   macro avg       0.57      0.52      0.49       360
weighted avg       0.69      0.58      0.59       360
",0.4571428571428571,0.7204030226700252,0.282051282051282
randomforest,False,True,"              precision    recall  f1-score   support

        news       0.32      0.86      0.47        72
     opinion       0.85      0.56      0.67       236
   fake_news       0.20      0.06      0.09        52

    accuracy                           0.54       360
   macro avg       0.46      0.49      0.41       360
weighted avg       0.65      0.54      0.55       360
",0.4714828897338404,0.6717948717948717,0.0895522388059701
randomforest,False,True,"              precision    recall  f1-score   support

        news       0.32      0.86      0.46        65
     opinion       0.88      0.56      0.68       240
   fake_news       0.42      0.24      0.30        55

    accuracy                           0.56       360
   macro avg       0.54      0.55      0.48       360
weighted avg       0.71      0.56      0.59       360
",0.4628099173553719,0.6836734693877551,0.3023255813953488
randomforest,True,False,"              precision    recall  f1-score   support

        news       0.53      0.60      0.56        84
     opinion       0.83      0.79      0.81       229
   fake_news       0.40      0.40      0.40        47

    accuracy                           0.70       360
   macro avg       0.59      0.60      0.59       360
weighted avg       0.71      0.70      0.70       360
",0.5617977528089887,0.8143176733780759,0.3999999999999999
randomforest,True,False,"              precision    recall  f1-score   support

        news       0.42      0.62      0.50        65
     opinion       0.90      0.77      0.83       253
   fake_news       0.29      0.33      0.31        42

    accuracy                           0.69       360
   macro avg       0.53      0.57      0.54       360
weighted avg       0.74      0.69      0.71       360
",0.5,0.8272921108742004,0.3076923076923076
randomforest,True,False,"              precision    recall  f1-score   support

        news       0.47      0.56      0.51        81
     opinion       0.86      0.77      0.81       232
   fake_news       0.33      0.40      0.37        47

    accuracy                           0.68       360
   macro avg       0.56      0.58      0.56       360
weighted avg       0.70      0.68      0.69       360
",0.5113636363636364,0.8136363636363637,0.3653846153846153
randomforest,True,False,"              precision    recall  f1-score   support

        news       0.45      0.63      0.52        73
     opinion       0.85      0.73      0.79       240
   fake_news       0.29      0.32      0.30        47

    accuracy                           0.66       360
   macro avg       0.53      0.56      0.54       360
weighted avg       0.70      0.66      0.67       360
",0.5227272727272727,0.7865168539325843,0.303030303030303
randomforest,True,False,"              precision    recall  f1-score   support

        news       0.44      0.61      0.51        64
     opinion       0.85      0.78      0.81       248
   fake_news       0.35      0.31      0.33        48

    accuracy                           0.69       360
   macro avg       0.54      0.57      0.55       360
weighted avg       0.71      0.69      0.69       360
",0.5098039215686275,0.8109243697478992,0.3296703296703296
randomforest,True,False,"              precision    recall  f1-score   support

        news       0.49      0.57      0.53        68
     opinion       0.85      0.79      0.82       244
   fake_news       0.37      0.42      0.39        48

    accuracy                           0.70       360
   macro avg       0.57      0.59      0.58       360
weighted avg       0.72      0.70      0.71       360
",0.5306122448979592,0.8195329087048832,0.392156862745098
randomforest,True,False,"              precision    recall  f1-score   support

        news       0.45      0.63      0.53        67
     opinion       0.85      0.76      0.80       250
   fake_news       0.39      0.40      0.39        43

    accuracy                           0.69       360
   macro avg       0.56      0.59      0.57       360
weighted avg       0.72      0.69      0.70       360
",0.525,0.8033826638477801,0.3908045977011494
randomforest,True,False,"              precision    recall  f1-score   support

        news       0.41      0.49      0.45        75
     opinion       0.78      0.75      0.76       227
   fake_news       0.37      0.33      0.35        58

    accuracy                           0.63       360
   macro avg       0.52      0.52      0.52       360
weighted avg       0.64      0.63      0.63       360
",0.4484848484848485,0.7640449438202247,0.3454545454545454
randomforest,True,False,"              precision    recall  f1-score   support

        news       0.44      0.64      0.52        72
     opinion       0.82      0.76      0.79       236
   fake_news       0.24      0.17      0.20        52

    accuracy                           0.65       360
   macro avg       0.50      0.52      0.50       360
weighted avg       0.66      0.65      0.65       360
",0.519774011299435,0.7885462555066078,0.2022471910112359
randomforest,True,False,"              precision    recall  f1-score   support

        news       0.39      0.65      0.49        65
     opinion       0.83      0.72      0.77       240
   fake_news       0.32      0.25      0.28        55

    accuracy                           0.64       360
   macro avg       0.51      0.54      0.51       360
weighted avg       0.67      0.64      0.65       360
",0.4883720930232558,0.7706013363028953,0.2828282828282828
randomforest,True,True,"              precision    recall  f1-score   support

        news       0.50      0.60      0.54        84
     opinion       0.83      0.79      0.81       229
   fake_news       0.40      0.36      0.38        47

    accuracy                           0.69       360
   macro avg       0.58      0.58      0.58       360
weighted avg       0.69      0.69      0.69       360
",0.5434782608695652,0.8053691275167785,0.3820224719101123
randomforest,True,True,"              precision    recall  f1-score   support

        news       0.47      0.68      0.55        65
     opinion       0.90      0.78      0.83       253
   fake_news       0.26      0.29      0.27        42

    accuracy                           0.70       360
   macro avg       0.54      0.58      0.55       360
weighted avg       0.74      0.70      0.72       360
",0.5534591194968554,0.8329809725158562,0.2727272727272727
randomforest,True,True,"              precision    recall  f1-score   support

        news       0.49      0.60      0.54        81
     opinion       0.85      0.78      0.81       232
   fake_news       0.31      0.32      0.31        47

    accuracy                           0.68       360
   macro avg       0.55      0.57      0.56       360
weighted avg       0.70      0.68      0.69       360
",0.5444444444444444,0.8108108108108107,0.3125
randomforest,True,True,"              precision    recall  f1-score   support

        news       0.43      0.62      0.51        73
     opinion       0.86      0.75      0.80       240
   fake_news       0.28      0.28      0.28        47

    accuracy                           0.66       360
   macro avg       0.52      0.55      0.53       360
weighted avg       0.70      0.66      0.67       360
",0.5084745762711865,0.7999999999999999,0.2795698924731182
randomforest,True,True,"              precision    recall  f1-score   support

        news       0.42      0.59      0.49        64
     opinion       0.84      0.79      0.82       248
   fake_news       0.41      0.29      0.34        48

    accuracy                           0.69       360
   macro avg       0.56      0.56      0.55       360
weighted avg       0.71      0.69      0.69       360
",0.4903225806451612,0.8157349896480331,0.3414634146341463
randomforest,True,True,"              precision    recall  f1-score   support

        news       0.44      0.54      0.49        68
     opinion       0.85      0.78      0.81       244
   fake_news       0.37      0.40      0.38        48

    accuracy                           0.69       360
   macro avg       0.55      0.57      0.56       360
weighted avg       0.71      0.69      0.70       360
",0.4868421052631579,0.8144989339019191,0.3838383838383838
randomforest,True,True,"              precision    recall  f1-score   support

        news       0.46      0.66      0.54        67
     opinion       0.87      0.77      0.82       250
   fake_news       0.40      0.40      0.40        43

    accuracy                           0.70       360
   macro avg       0.57      0.61      0.58       360
weighted avg       0.74      0.70      0.71       360
",0.5398773006134969,0.8152866242038217,0.3953488372093023
randomforest,True,True,"              precision    recall  f1-score   support

        news       0.42      0.53      0.47        75
     opinion       0.79      0.76      0.77       227
   fake_news       0.38      0.31      0.34        58

    accuracy                           0.64       360
   macro avg       0.53      0.53      0.53       360
weighted avg       0.65      0.64      0.64       360
",0.4705882352941176,0.7730337078651686,0.3428571428571428
randomforest,True,True,"              precision    recall  f1-score   support

        news       0.41      0.56      0.47        72
     opinion       0.81      0.76      0.79       236
   fake_news       0.25      0.19      0.22        52

    accuracy                           0.64       360
   macro avg       0.49      0.50      0.49       360
weighted avg       0.65      0.64      0.64       360
",0.4705882352941176,0.7860262008733624,0.2173913043478261
randomforest,True,True,"              precision    recall  f1-score   support

        news       0.37      0.58      0.45        65
     opinion       0.82      0.74      0.78       240
   fake_news       0.43      0.33      0.37        55

    accuracy                           0.65       360
   macro avg       0.54      0.55      0.53       360
weighted avg       0.68      0.65      0.66       360
",0.4523809523809524,0.778021978021978,0.3711340206185567
xgboost,False,False,"              precision    recall  f1-score   support

        news       0.62      0.48      0.54        84
     opinion       0.75      0.90      0.82       229
   fake_news       0.50      0.21      0.30        47

    accuracy                           0.71       360
   macro avg       0.62      0.53      0.55       360
weighted avg       0.69      0.71      0.69       360
",0.5369127516778524,0.8214285714285714,0.2985074626865672
xgboost,False,False,"              precision    recall  f1-score   support

        news       0.50      0.46      0.48        65
     opinion       0.80      0.92      0.86       253
   fake_news       0.20      0.05      0.08        42

    accuracy                           0.74       360
   macro avg       0.50      0.48      0.47       360
weighted avg       0.68      0.74      0.70       360
",0.48,0.858195211786372,0.0769230769230769
xgboost,False,False,"              precision    recall  f1-score   support

        news       0.65      0.49      0.56        81
     opinion       0.76      0.91      0.83       232
   fake_news       0.45      0.21      0.29        47

    accuracy                           0.73       360
   macro avg       0.62      0.54      0.56       360
weighted avg       0.70      0.72      0.70       360
",0.5594405594405595,0.8307086614173228,0.289855072463768
xgboost,False,False,"              precision    recall  f1-score   support

        news       0.52      0.40      0.45        73
     opinion       0.78      0.90      0.83       240
   fake_news       0.41      0.23      0.30        47

    accuracy                           0.71       360
   macro avg       0.57      0.51      0.53       360
weighted avg       0.68      0.71      0.68       360
",0.4496124031007752,0.8317214700193424,0.2972972972972972
xgboost,False,False,"              precision    recall  f1-score   support

        news       0.48      0.38      0.42        64
     opinion       0.80      0.92      0.85       248
   fake_news       0.55      0.25      0.34        48

    accuracy                           0.74       360
   macro avg       0.61      0.52      0.54       360
weighted avg       0.71      0.74      0.71       360
",0.4210526315789473,0.8544776119402984,0.3428571428571428
xgboost,False,False,"              precision    recall  f1-score   support

        news       0.48      0.32      0.39        68
     opinion       0.78      0.93      0.85       244
   fake_news       0.62      0.31      0.42        48

    accuracy                           0.73       360
   macro avg       0.63      0.52      0.55       360
weighted avg       0.70      0.73      0.70       360
",0.3859649122807018,0.8464419475655431,0.4166666666666667
xgboost,False,False,"              precision    recall  f1-score   support

        news       0.58      0.46      0.52        67
     opinion       0.79      0.93      0.86       250
   fake_news       0.62      0.19      0.29        43

    accuracy                           0.76       360
   macro avg       0.66      0.53      0.55       360
weighted avg       0.73      0.76      0.73       360
",0.5166666666666667,0.8566176470588235,0.2857142857142857
xgboost,False,False,"              precision    recall  f1-score   support

        news       0.51      0.44      0.47        75
     opinion       0.74      0.90      0.81       227
   fake_news       0.67      0.24      0.35        58

    accuracy                           0.70       360
   macro avg       0.64      0.53      0.55       360
weighted avg       0.68      0.70      0.67       360
",0.4714285714285715,0.8143712574850299,0.3544303797468354
xgboost,False,False,"              precision    recall  f1-score   support

        news       0.56      0.42      0.48        72
     opinion       0.72      0.91      0.81       236
   fake_news       0.33      0.06      0.10        52

    accuracy                           0.69       360
   macro avg       0.54      0.46      0.46       360
weighted avg       0.63      0.69      0.64       360
",0.4761904761904762,0.8067542213883677,0.0983606557377049
xgboost,False,False,"              precision    recall  f1-score   support

        news       0.47      0.42      0.44        65
     opinion       0.77      0.90      0.83       240
   fake_news       0.50      0.20      0.29        55

    accuracy                           0.70       360
   macro avg       0.58      0.50      0.52       360
weighted avg       0.67      0.70      0.67       360
",0.4390243902439024,0.8269230769230769,0.2857142857142857
xgboost,False,True,"              precision    recall  f1-score   support

        news       0.47      0.73      0.57        84
     opinion       0.85      0.64      0.73       229
   fake_news       0.28      0.34      0.31        47

    accuracy                           0.62       360
   macro avg       0.53      0.57      0.54       360
weighted avg       0.69      0.62      0.64       360
",0.5674418604651164,0.7331670822942643,0.3076923076923076
xgboost,False,True,"              precision    recall  f1-score   support

        news       0.37      0.66      0.48        65
     opinion       0.92      0.67      0.78       253
   fake_news       0.22      0.31      0.26        42

    accuracy                           0.63       360
   macro avg       0.50      0.55      0.50       360
weighted avg       0.74      0.63      0.66       360
",0.4751381215469613,0.776255707762557,0.2574257425742574
xgboost,False,True,"              precision    recall  f1-score   support

        news       0.43      0.73      0.54        81
     opinion       0.88      0.64      0.74       232
   fake_news       0.30      0.34      0.32        47

    accuracy                           0.62       360
   macro avg       0.53      0.57      0.53       360
weighted avg       0.70      0.62      0.64       360
",0.5388127853881278,0.7400000000000001,0.3168316831683168
xgboost,False,True,"              precision    recall  f1-score   support

        news       0.40      0.74      0.52        73
     opinion       0.89      0.57      0.69       240
   fake_news       0.26      0.40      0.32        47

    accuracy                           0.58       360
   macro avg       0.52      0.57      0.51       360
weighted avg       0.71      0.58      0.61       360
",0.5217391304347826,0.6921119592875318,0.3166666666666666
xgboost,False,True,"              precision    recall  f1-score   support

        news       0.35      0.69      0.46        64
     opinion       0.88      0.68      0.76       248
   fake_news       0.29      0.25      0.27        48

    accuracy                           0.62       360
   macro avg       0.50      0.54      0.50       360
weighted avg       0.70      0.62      0.64       360
",0.4607329842931937,0.7636363636363636,0.2696629213483146
xgboost,False,True,"              precision    recall  f1-score   support

        news       0.36      0.65      0.47        68
     opinion       0.88      0.64      0.74       244
   fake_news       0.31      0.40      0.35        48

    accuracy                           0.61       360
   macro avg       0.52      0.56      0.52       360
weighted avg       0.71      0.61      0.64       360
",0.4656084656084656,0.7410926365795726,0.3454545454545454
xgboost,False,True,"              precision    recall  f1-score   support

        news       0.37      0.69      0.48        67
     opinion       0.88      0.66      0.75       250
   fake_news       0.27      0.30      0.29        43

    accuracy                           0.62       360
   macro avg       0.51      0.55      0.51       360
weighted avg       0.71      0.62      0.64       360
",0.4791666666666666,0.7505720823798627,0.2857142857142857
xgboost,False,True,"              precision    recall  f1-score   support

        news       0.34      0.61      0.44        75
     opinion       0.81      0.63      0.71       227
   fake_news       0.43      0.34      0.38        58

    accuracy                           0.58       360
   macro avg       0.53      0.53      0.51       360
weighted avg       0.65      0.58      0.60       360
",0.4360189573459715,0.712871287128713,0.380952380952381
xgboost,False,True,"              precision    recall  f1-score   support

        news       0.33      0.67      0.44        72
     opinion       0.84      0.58      0.68       236
   fake_news       0.22      0.21      0.21        52

    accuracy                           0.54       360
   macro avg       0.46      0.48      0.45       360
weighted avg       0.65      0.54      0.57       360
",0.4383561643835615,0.6834170854271356,0.2135922330097087
xgboost,False,True,"              precision    recall  f1-score   support

        news       0.35      0.71      0.46        65
     opinion       0.87      0.57      0.69       240
   fake_news       0.29      0.36      0.32        55

    accuracy                           0.56       360
   macro avg       0.50      0.55      0.49       360
weighted avg       0.69      0.56      0.59       360
",0.4646464646464646,0.690176322418136,0.32
xgboost,True,False,"              precision    recall  f1-score   support

        news       0.53      0.55      0.54        84
     opinion       0.80      0.83      0.81       229
   fake_news       0.37      0.30      0.33        47

    accuracy                           0.69       360
   macro avg       0.57      0.56      0.56       360
weighted avg       0.68      0.69      0.69       360
",0.5380116959064327,0.8146551724137931,0.3294117647058823
xgboost,True,False,"              precision    recall  f1-score   support

        news       0.47      0.55      0.51        65
     opinion       0.86      0.83      0.85       253
   fake_news       0.25      0.24      0.24        42

    accuracy                           0.71       360
   macro avg       0.53      0.54      0.53       360
weighted avg       0.72      0.71      0.72       360
",0.5070422535211268,0.846774193548387,0.2439024390243902
xgboost,True,False,"              precision    recall  f1-score   support

        news       0.58      0.60      0.59        81
     opinion       0.82      0.80      0.81       232
   fake_news       0.31      0.32      0.31        47

    accuracy                           0.69       360
   macro avg       0.57      0.58      0.57       360
weighted avg       0.70      0.69      0.70       360
",0.5903614457831325,0.8122270742358078,0.3125
xgboost,True,False,"              precision    recall  f1-score   support

        news       0.45      0.52      0.48        73
     opinion       0.82      0.78      0.80       240
   fake_news       0.32      0.32      0.32        47

    accuracy                           0.67       360
   macro avg       0.53      0.54      0.53       360
weighted avg       0.68      0.67      0.67       360
",0.481012658227848,0.7991452991452992,0.3191489361702128
xgboost,True,False,"              precision    recall  f1-score   support

        news       0.41      0.55      0.47        64
     opinion       0.83      0.80      0.81       248
   fake_news       0.36      0.27      0.31        48

    accuracy                           0.68       360
   macro avg       0.53      0.54      0.53       360
weighted avg       0.69      0.68      0.69       360
",0.4666666666666666,0.8148148148148147,0.3095238095238095
xgboost,True,False,"              precision    recall  f1-score   support

        news       0.46      0.47      0.46        68
     opinion       0.83      0.83      0.83       244
   fake_news       0.37      0.35      0.36        48

    accuracy                           0.70       360
   macro avg       0.55      0.55      0.55       360
weighted avg       0.70      0.70      0.70       360
",0.4637681159420289,0.8278688524590164,0.3617021276595745
xgboost,True,False,"              precision    recall  f1-score   support

        news       0.45      0.55      0.50        67
     opinion       0.84      0.79      0.82       250
   fake_news       0.35      0.35      0.35        43

    accuracy                           0.69       360
   macro avg       0.55      0.56      0.55       360
weighted avg       0.71      0.69      0.70       360
",0.4966442953020134,0.8164948453608248,0.3488372093023256
xgboost,True,False,"              precision    recall  f1-score   support

        news       0.46      0.53      0.49        75
     opinion       0.78      0.81      0.79       227
   fake_news       0.47      0.29      0.36        58

    accuracy                           0.67       360
   macro avg       0.57      0.55      0.55       360
weighted avg       0.66      0.67      0.66       360
",0.4938271604938271,0.793103448275862,0.3617021276595744
xgboost,True,False,"              precision    recall  f1-score   support

        news       0.45      0.54      0.49        72
     opinion       0.79      0.80      0.79       236
   fake_news       0.30      0.21      0.25        52

    accuracy                           0.66       360
   macro avg       0.51      0.52      0.51       360
weighted avg       0.65      0.66      0.66       360
",0.4936708860759493,0.7949260042283298,0.247191011235955
xgboost,True,False,"              precision    recall  f1-score   support

        news       0.43      0.58      0.49        65
     opinion       0.82      0.76      0.79       240
   fake_news       0.37      0.33      0.35        55

    accuracy                           0.66       360
   macro avg       0.54      0.56      0.54       360
weighted avg       0.68      0.66      0.67       360
",0.4935064935064934,0.7922077922077922,0.3461538461538461
xgboost,True,True,"              precision    recall  f1-score   support

        news       0.50      0.50      0.50        84
     opinion       0.79      0.83      0.81       229
   fake_news       0.40      0.30      0.34        47

    accuracy                           0.69       360
   macro avg       0.56      0.54      0.55       360
weighted avg       0.67      0.69      0.68       360
",0.5,0.8127659574468085,0.34146341463414637
xgboost,True,True,"              precision    recall  f1-score   support

        news       0.52      0.62      0.56        65
     opinion       0.87      0.86      0.87       253
   fake_news       0.31      0.24      0.27        42

    accuracy                           0.74       360
   macro avg       0.57      0.57      0.57       360
weighted avg       0.74      0.74      0.74       360
",0.5633802816901409,0.8650793650793651,0.27027027027027023
xgboost,True,True,"              precision    recall  f1-score   support

        news       0.59      0.54      0.57        81
     opinion       0.81      0.83      0.82       232
   fake_news       0.31      0.32      0.32        47

    accuracy                           0.70       360
   macro avg       0.57      0.56      0.57       360
weighted avg       0.69      0.70      0.70       360
",0.567741935483871,0.8170212765957446,0.3157894736842105
xgboost,True,True,"              precision    recall  f1-score   support

        news       0.49      0.49      0.49        73
     opinion       0.81      0.81      0.81       240
   fake_news       0.32      0.32      0.32        47

    accuracy                           0.68       360
   macro avg       0.54      0.54      0.54       360
weighted avg       0.68      0.68      0.68       360
",0.4931506849315068,0.8125,0.3191489361702128
xgboost,True,True,"              precision    recall  f1-score   support

        news       0.47      0.55      0.50        64
     opinion       0.84      0.85      0.85       248
   fake_news       0.47      0.31      0.38        48

    accuracy                           0.73       360
   macro avg       0.59      0.57      0.57       360
weighted avg       0.72      0.73      0.72       360
",0.5035971223021581,0.8463073852295409,0.375
xgboost,True,True,"              precision    recall  f1-score   support

        news       0.46      0.49      0.47        68
     opinion       0.82      0.82      0.82       244
   fake_news       0.40      0.38      0.39        48

    accuracy                           0.70       360
   macro avg       0.56      0.56      0.56       360
weighted avg       0.70      0.70      0.70       360
",0.4748201438848921,0.819672131147541,0.38709677419354843
xgboost,True,True,"              precision    recall  f1-score   support

        news       0.47      0.54      0.50        67
     opinion       0.84      0.83      0.84       250
   fake_news       0.38      0.35      0.37        43

    accuracy                           0.72       360
   macro avg       0.57      0.57      0.57       360
weighted avg       0.72      0.72      0.72       360
",0.5034965034965035,0.8363636363636363,0.3658536585365854
xgboost,True,True,"              precision    recall  f1-score   support

        news       0.45      0.48      0.46        75
     opinion       0.77      0.83      0.80       227
   fake_news       0.56      0.33      0.41        58

    accuracy                           0.68       360
   macro avg       0.59      0.55      0.56       360
weighted avg       0.67      0.68      0.67       360
",0.4645161290322581,0.7991543340380549,0.4130434782608695
xgboost,True,True,"              precision    recall  f1-score   support

        news       0.44      0.54      0.49        72
     opinion       0.80      0.81      0.80       236
   fake_news       0.21      0.13      0.16        52

    accuracy                           0.66       360
   macro avg       0.48      0.49      0.48       360
weighted avg       0.64      0.66      0.65       360
",0.48749999999999993,0.8016877637130803,0.1627906976744186
xgboost,True,True,"              precision    recall  f1-score   support

        news       0.41      0.48      0.44        65
     opinion       0.78      0.77      0.78       240
   fake_news       0.29      0.25      0.27        55

    accuracy                           0.64       360
   macro avg       0.49      0.50      0.50       360
weighted avg       0.64      0.64      0.64       360
",0.43971631205673756,0.777310924369748,0.27184466019417475
